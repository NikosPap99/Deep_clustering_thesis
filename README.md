# Deep_clustering_thesis

- The MLP experiment notebooks' names start with the dataset name.
- The autoencoder-trained-with-centroids experiment notebooks' names start with the word 'autoencoder'.
- The autoencoder-trained-without-centroids experiment notebooks' names start with the phrase 'autoencoder_no_centroids'.
- Information about each notebook's content:
  1. The Import section has all the imports needed in the first cell and then the dataset download. The functions I use extract the dataset files from my drive, using their paths. Those functions need to be replaced for the notebooks to run outside of Google Colab. If the user intends to run the files from Google Colab, they can mount their drive (using the option 'Mount Drive' from the 'Files' section of the interface) and alter the path give in the 'notebook_path' and 'data_path' variables in order for them to match their own paths.
  2. The second section has all MLP/autoencoder declarations and the functions of the Hungarian Algorithm etc. From there, the user can alter the neural network architectures.
  3. The third section is the experiment part. The first cells run t-SNE and then the main 'run_experiment' cell has the experiment function for certain adjustable architecture parameters (# of neurons and epochs only) and the hyperparameter K. Also, the name of the datapoints and labels are passed. Inside the experiment, there are certain parts in comments, like the scaling in the latent space and the t-SNE execution on the latent space (in some notebooks this might be without comments). Normally, after the function declaration there are executions for various values of the hyperparameter K and then boxplots based on those executions.
  4. The fourth section has the code for the overclustering criterion based on silhouette score (otherwise named 'silhouette factor' at the time of coding). The process has been split in functions, one for each step. Then the main function 'silhouette_factor' runs all the steps and finally there is a cell used for plotting.
